{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import IPython\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_credit_application = pd.read_csv('data/application_train.csv')\n",
    "raw_test_credit_application = pd.read_csv('data/application_test.csv')\n",
    "\n",
    "# raw_bureau = pd.read_csv('data/bureau.csv')\n",
    "# raw_bureau_balance = pd.read_csv('data/bureau_balance.csv')\n",
    "# raw_credit_card_balance = pd.read_csv('data/credit_card_balance.csv')\n",
    "# raw_installments_payments = pd.read_csv('data/installments_payments.csv')\n",
    "# raw_pos_cash_balance = pd.read_csv('data/pos_cash_balance.csv')\n",
    "# raw_previous_application = pd.read_csv('data/previous_application.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_train_credit_application.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# raw_test_credit_application.describe()\n",
    "# raw_train_credit_application.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# raw_test_credit_application.describe()\n",
    "# raw_test_credit_application.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_credit_application['TARGET'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=[15, 100])\n",
    "columns = ['NAME_CONTRACT_TYPE', 'CODE_GENDER',\n",
    "           'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'CNT_CHILDREN',\n",
    "           'NAME_TYPE_SUITE', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE',\n",
    "           'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'FLAG_MOBIL',\n",
    "           'FLAG_EMP_PHONE', 'FLAG_WORK_PHONE', 'FLAG_CONT_MOBILE',\n",
    "           'FLAG_PHONE', 'FLAG_EMAIL', 'FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_3',\n",
    "           'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_6',\n",
    "           'FLAG_DOCUMENT_7', 'FLAG_DOCUMENT_8', 'FLAG_DOCUMENT_9',\n",
    "           'FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_12',\n",
    "           'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_15',\n",
    "           'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17', 'FLAG_DOCUMENT_18',\n",
    "           'FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_20', 'FLAG_DOCUMENT_21'\n",
    "          ]\n",
    "row_no = 20\n",
    "column_no = 3\n",
    "for index, column in enumerate(columns):\n",
    "    plt.subplot(row_no, column_no, index + 1)\n",
    "    plt.title(column)\n",
    "    raw_train_credit_application.groupby([column]).TARGET.value_counts().plot(kind='bar')\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_credit_application = raw_train_credit_application.reindex(np.random.permutation(raw_train_credit_application.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check distribution if the randomization is fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_count = raw_train_credit_application['SK_ID_CURR'].count()\n",
    "training_count = math.ceil(total_count * 0.75)\n",
    "validation_count = math.floor(total_count * 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_credit_application = raw_train_credit_application.head(training_count)\n",
    "validation_credit_application = raw_train_credit_application.tail(validation_count)\n",
    "testing_credit_application = raw_test_credit_application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ['FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_3',\n",
    "       'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_6',\n",
    "       'FLAG_DOCUMENT_7', 'FLAG_DOCUMENT_8', 'FLAG_DOCUMENT_9',\n",
    "       'FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_12',\n",
    "       'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_15',\n",
    "       'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17', 'FLAG_DOCUMENT_18',\n",
    "       'FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_20', 'FLAG_DOCUMENT_21']\n",
    "for i in a:\n",
    "    print('new_data[\\'%s\\'] = df[\\'%s\\']' % (i, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, dataframe=False):\n",
    "    new_ids = df['SK_ID_CURR'].to_frame()\n",
    "    new_data = pd.DataFrame()\n",
    "    if 'TARGET' in df.columns:\n",
    "        new_targets = df['TARGET'].to_frame()\n",
    "    else:\n",
    "        new_targets = None\n",
    "    \n",
    "    # NAME_CONTRACT_TYPE\n",
    "    new_data['NAME_CONTRACT_TYPE'] = df['NAME_CONTRACT_TYPE']\n",
    "    \n",
    "    # CODE_GENDER\n",
    "    new_data['CODE_GENDER'] = df['CODE_GENDER'].apply(lambda val: 'F' if val == 'XNA' else val)\n",
    "        \n",
    "    # FLAGS\n",
    "    new_data['FLAG_OWN_CAR'] = df['FLAG_OWN_CAR'].apply(lambda val: '0' if val == 'N' else 1)\n",
    "    new_data['FLAG_OWN_REALTY'] = df['FLAG_OWN_REALTY'].apply(lambda val: '0' if val == 'N' else 1)\n",
    "    new_data['FLAG_MOBIL'] = df['FLAG_MOBIL']\n",
    "    new_data['FLAG_EMP_PHONE'] = df['FLAG_EMP_PHONE']\n",
    "    new_data['FLAG_WORK_PHONE'] = df['FLAG_WORK_PHONE']\n",
    "    new_data['FLAG_CONT_MOBILE'] = df['FLAG_CONT_MOBILE']\n",
    "    new_data['FLAG_PHONE'] = df['FLAG_PHONE']\n",
    "    new_data['FLAG_EMAIL'] = df['FLAG_EMAIL']\n",
    "#     new_data['FLAG_DOCUMENT_2'] = df['FLAG_DOCUMENT_2']\n",
    "#     new_data['FLAG_DOCUMENT_3'] = df['FLAG_DOCUMENT_3']\n",
    "#     new_data['FLAG_DOCUMENT_4'] = df['FLAG_DOCUMENT_4']\n",
    "#     new_data['FLAG_DOCUMENT_5'] = df['FLAG_DOCUMENT_5']\n",
    "#     new_data['FLAG_DOCUMENT_6'] = df['FLAG_DOCUMENT_6']\n",
    "#     new_data['FLAG_DOCUMENT_7'] = df['FLAG_DOCUMENT_7']\n",
    "#     new_data['FLAG_DOCUMENT_8'] = df['FLAG_DOCUMENT_8']\n",
    "#     new_data['FLAG_DOCUMENT_9'] = df['FLAG_DOCUMENT_9']\n",
    "#     new_data['FLAG_DOCUMENT_10'] = df['FLAG_DOCUMENT_10']\n",
    "#     new_data['FLAG_DOCUMENT_11'] = df['FLAG_DOCUMENT_11']\n",
    "#     new_data['FLAG_DOCUMENT_12'] = df['FLAG_DOCUMENT_12']\n",
    "#     new_data['FLAG_DOCUMENT_13'] = df['FLAG_DOCUMENT_13']\n",
    "#     new_data['FLAG_DOCUMENT_14'] = df['FLAG_DOCUMENT_14']\n",
    "#     new_data['FLAG_DOCUMENT_15'] = df['FLAG_DOCUMENT_15']\n",
    "#     new_data['FLAG_DOCUMENT_16'] = df['FLAG_DOCUMENT_16']\n",
    "#     new_data['FLAG_DOCUMENT_17'] = df['FLAG_DOCUMENT_17']\n",
    "#     new_data['FLAG_DOCUMENT_18'] = df['FLAG_DOCUMENT_18']\n",
    "#     new_data['FLAG_DOCUMENT_19'] = df['FLAG_DOCUMENT_19']\n",
    "#     new_data['FLAG_DOCUMENT_20'] = df['FLAG_DOCUMENT_20']\n",
    "#     new_data['FLAG_DOCUMENT_21'] = df['FLAG_DOCUMENT_21']\n",
    "    \n",
    "    new_data = pd.get_dummies(new_data, columns=['NAME_CONTRACT_TYPE', 'CODE_GENDER'])\n",
    "    \n",
    "    if dataframe:\n",
    "        try:\n",
    "            new_ids = new_ids.values\n",
    "        except Exception as e:\n",
    "            new_ids = None\n",
    "        \n",
    "        try:\n",
    "            new_data = new_data.values\n",
    "        except Exception as e:\n",
    "            new_data = None\n",
    "            \n",
    "        try:\n",
    "            new_targets = new_targets.values\n",
    "            new_targets = new_targets.reshape(-1, )\n",
    "        except Exception as e:\n",
    "            new_targets = None\n",
    "    \n",
    "    return new_ids, new_data, new_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ids, training_data, training_targets = preprocess_data(training_credit_application, dataframe=False)\n",
    "validation_ids, validation_data, validation_targets = preprocess_data(validation_credit_application, dataframe=False)\n",
    "testing_ids, testing_data, testing_targets = preprocess_data(testing_credit_application, dataframe=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ids, training_data, training_targets = preprocess_data(training_credit_application, dataframe=True)\n",
    "validation_ids, validation_data, validation_targets = preprocess_data(validation_credit_application, dataframe=True)\n",
    "testing_ids, testing_data, testing_targets = preprocess_data(testing_credit_application, dataframe=True)\n",
    "\n",
    "training_targets_onehot = (preprocessing.OneHotEncoder().fit_transform(training_targets.reshape(-1, 1))).toarray()\n",
    "validation_targets_onehot = (preprocessing.OneHotEncoder().fit_transform(validation_targets.reshape(-1, 1))).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_targets_onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model, ensemble, svm\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sgd_classifier =  linear_model.SGDClassifier()\n",
    "sgd_classifier.fit(training_data, training_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "svm_classifier = svm.SVC(kernel='rbf')\n",
    "svm_classifier.fit(training_data, training_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_metric(y_true, y_pred):\n",
    "    return tf.Variable(metrics.roc_auc_score(y_true, y_pred), name='auc_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_activation = 'sigmoid'\n",
    "default_last_activation = 'sigmoid'\n",
    "default_batch_size = 1000\n",
    "default_epochs = 1000\n",
    "\n",
    "default_dnn_classifier_settings = [\n",
    "    # Adam\n",
    "    {'optimizer': optimizers.Adam(), 'batch_size': default_batch_size, 'epochs': default_epochs, \n",
    "     'activation': default_activation, 'last_activation': default_last_activation,\n",
    "     'acc': None, 'val_acc': None, 'history': None, 'auc': None, 'val_auc': None},\n",
    "    \n",
    "    # SGD\n",
    "    {'optimizer': optimizers.SGD(momentum=0.1), 'batch_size': default_batch_size, 'epochs': 1000,\n",
    "     'activation': default_activation, 'last_activation': default_last_activation,\n",
    "     'acc': None, 'val_acc': None, 'history': None, 'auc': None, 'val_auc': None},\n",
    "    \n",
    "    # Adagrad\n",
    "    {'optimizer': optimizers.Adagrad(), 'batch_size': default_batch_size, 'epochs': default_epochs, \n",
    "     'activation': default_activation, 'last_activation': default_last_activation,\n",
    "     'acc': None, 'val_acc': None, 'history': None, 'auc': None, 'val_auc': None},\n",
    "    \n",
    "    # RMSprop\n",
    "    {'optimizer': optimizers.RMSprop(), 'batch_size': default_batch_size, 'epochs': default_epochs, \n",
    "     'activation': default_activation, 'last_activation': default_last_activation,\n",
    "     'acc': None, 'val_acc': None, 'history': None, 'auc': None, 'val_auc': None},\n",
    "    \n",
    "    # Adamax\n",
    "    {'optimizer': optimizers.Adamax(), 'batch_size': default_batch_size, 'epochs': default_epochs, \n",
    "     'activation': default_activation, 'last_activation': default_last_activation,\n",
    "     'acc': None, 'val_acc': None, 'history': None, 'auc': None, 'val_auc': None},\n",
    "    \n",
    "    # Nadam\n",
    "    {'optimizer': optimizers.Nadam(), 'batch_size': default_batch_size, 'epochs': default_epochs, \n",
    "     'activation': default_activation, 'last_activation': default_last_activation,\n",
    "     'acc': None, 'val_acc': None, 'history': None, 'auc': None, 'val_auc': None},\n",
    "]\n",
    "\n",
    "dnn_classifier_settings = []\n",
    "dnn_classifier_settings.extend(default_dnn_classifier_settings)\n",
    "\n",
    "new_settings = [\n",
    "]\n",
    "\n",
    "if len(new_settings) > 0:\n",
    "    dnn_classifier_settings.extend(new_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for index, dnn_classifier_setting in enumerate(dnn_classifier_settings):\n",
    "    if dnn_classifier_setting['acc'] is None and dnn_classifier_setting['val_acc'] is None and dnn_classifier_setting['history'] is None:\n",
    "        optimizer = dnn_classifier_setting['optimizer']\n",
    "        batch_size = dnn_classifier_setting['batch_size']\n",
    "        epochs = dnn_classifier_setting['epochs']\n",
    "        activation = dnn_classifier_setting['activation']\n",
    "        last_activation = dnn_classifier_setting['last_activation']\n",
    "\n",
    "        dnn_classifier = Sequential()\n",
    "        input_shape = (training_data.shape[1], )\n",
    "        dnn_classifier.add(Dense(128, activation=activation, input_shape=input_shape))\n",
    "        dnn_classifier.add(Dropout(rate=0.35))\n",
    "        dnn_classifier.add(Dense(128, activation=activation))\n",
    "        dnn_classifier.add(Dropout(rate=0.35))\n",
    "        dnn_classifier.add(Dense(64, activation=activation))\n",
    "        dnn_classifier.add(Dropout(rate=0.25))\n",
    "        dnn_classifier.add(Dense(2, activation=last_activation))\n",
    "        dnn_classifier.compile(loss='binary_crossentropy', \n",
    "                               optimizer=optimizer,\n",
    "                               metrics=['acc'])\n",
    "        history = dnn_classifier.fit(training_data, training_targets_onehot,\n",
    "                          epochs=epochs, batch_size=batch_size, verbose=1, shuffle=True,\n",
    "                          validation_data=(validation_data, validation_targets_onehot))\n",
    "\n",
    "        dnn_classifier_setting['history'] = history\n",
    "        \n",
    "        training_predictions = dnn_classifier.predict(training_data)\n",
    "        training_predictions = pd.DataFrame(training_predictions).apply(lambda val: 1.0 if val[1] > 0.50 else 0.0, axis=1)\n",
    "        \n",
    "        validation_predictions = dnn_classifier.predict(validation_data)\n",
    "        validation_predictions = pd.DataFrame(validation_predictions).apply(lambda val: 1.0 if val[1] > 0.50 else 0.0, axis=1)\n",
    "        \n",
    "        dnn_classifier_setting['acc'] = metrics.accuracy_score(training_targets, training_predictions)\n",
    "        dnn_classifier_setting['val_acc'] = metrics.accuracy_score(validation_targets, validation_predictions)\n",
    "        dnn_classifier_setting['auc'] = metrics.roc_auc_score(training_targets, training_predictions)\n",
    "        dnn_classifier_setting['val_auc'] = metrics.roc_auc_score(validation_targets, validation_predictions)\n",
    "\n",
    "    print('%2d: Optimizer: %10s; LR: %.5f; bs: %3d; epochs: %4d; acc: %.2f; val_acc: %.2f; auc: %.2f; val_auc: %.2f' % (index, \n",
    "                                                                                              type(dnn_classifier_setting['optimizer']).__name__, \n",
    "                                                                                              dnn_classifier_setting['optimizer'].get_config()['lr'], \n",
    "                                                                                              dnn_classifier_setting['batch_size'], \n",
    "                                                                                              dnn_classifier_setting['epochs'],\n",
    "                                                                                              dnn_classifier_setting['acc'], \n",
    "                                                                                              dnn_classifier_setting['val_acc'],\n",
    "                                                                                              dnn_classifier_setting['auc'],\n",
    "                                                                                              dnn_classifier_setting['val_auc']))\n",
    "\n",
    "IPython.display.Audio('http://www.pacdv.com/sounds/interface_sound_effects/sound94.wav', autoplay=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = dnn_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_predictions = classifier.predict(training_data)\n",
    "print(training_predictions)\n",
    "training_predictions = pd.DataFrame(training_predictions).apply(lambda val: 1.0 if val[1] > 0.1 else 0.0, axis=1)\n",
    "validation_predictions = classifier.predict(validation_data)\n",
    "validation_predictions = pd.DataFrame(validation_predictions).apply(lambda val: 1.0 if val[1] > 0.1 else 0.0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(training_targets).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_predictions.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.accuracy_score(training_targets, training_predictions))\n",
    "print(metrics.roc_auc_score(training_targets, training_predictions))\n",
    "print(metrics.accuracy_score(validation_targets, validation_predictions))\n",
    "print(metrics.roc_auc_score(validation_targets, validation_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare submission.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
