{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import IPython\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing, decomposition, discriminant_analysis, tree\n",
    "\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_credit_application = pd.read_csv('data/application_train.csv')\n",
    "raw_test_credit_application = pd.read_csv('data/application_test.csv')\n",
    "\n",
    "raw_bureau = pd.read_csv('data/bureau.csv')\n",
    "raw_bureau_balance = pd.read_csv('data/bureau_balance.csv')\n",
    "# raw_credit_card_balance = pd.read_csv('data/credit_card_balance.csv')\n",
    "# raw_installments_payments = pd.read_csv('data/installments_payments.csv')\n",
    "# raw_pos_cash_balance = pd.read_csv('data/pos_cash_balance.csv')\n",
    "raw_previous_application = pd.read_csv('data/previous_application.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_SK_ID_CURR = raw_train_credit_application['SK_ID_CURR'].unique()\n",
    "test_SK_ID_CURR = raw_test_credit_application['SK_ID_CURR'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1529043289.9913757\n",
      "10000 1529043456.30976\n"
     ]
    }
   ],
   "source": [
    "add_columns = [\n",
    "    'SK_ID_CURR',\n",
    "    \n",
    "    'BUR_credit_active',\n",
    "    'BUR_credit_closed',\n",
    "    'BUR_credit_sold',\n",
    "    'BUR_credit_bad_debt',\n",
    "    'BUR_sum_credit_day_overdue',\n",
    "    'BUR_mean_credit_day_overdue',\n",
    "    'BUR_credit_type_count',\n",
    "    'BUR_mean_days_credit_update',\n",
    "    'PREV_application_count',\n",
    "    'PREV_name_contract_type_count',\n",
    "    'PREV_mean_amount_credit',\n",
    "    'PREV_name_contract_status_approved_count',\n",
    "]\n",
    "\n",
    "add_train_credit_application = []\n",
    "index = 0\n",
    "for SK_ID_CURR in train_SK_ID_CURR:\n",
    "    if index % 10000 == 0:\n",
    "        print(index, time.time())\n",
    "    \n",
    "    # BUREAU\n",
    "    bureau_SK_ID_CURR = raw_bureau.loc[raw_bureau['SK_ID_CURR'] == SK_ID_CURR]\n",
    "    \n",
    "    credit_active_value_counts = bureau_SK_ID_CURR['CREDIT_ACTIVE'].value_counts()\n",
    "    BUR_credit_active = credit_active_value_counts['Active'] if 'Active' in credit_active_value_counts else 0\n",
    "    BUR_credit_closed = credit_active_value_counts['Closed'] if 'Closed' in credit_active_value_counts else 0\n",
    "    BUR_credit_sold = credit_active_value_counts['Sold'] if 'Sold' in credit_active_value_counts else 0\n",
    "    BUR_credit_bad_debt = credit_active_value_counts['Bad Debt'] if 'Bad Debt' in credit_active_value_counts else 0\n",
    "    \n",
    "    BUR_sum_credit_day_overdue = bureau_SK_ID_CURR['CREDIT_DAY_OVERDUE'].sum()\n",
    "    BUR_mean_credit_day_overdue = bureau_SK_ID_CURR['CREDIT_DAY_OVERDUE'].mean()\n",
    "    \n",
    "    BUR_credit_type_count = bureau_SK_ID_CURR['CREDIT_TYPE'].value_counts().count()\n",
    "    \n",
    "    BUR_mean_days_credit_update = bureau_SK_ID_CURR['DAYS_CREDIT_UPDATE'].mean()\n",
    "    \n",
    "    \n",
    "    # PREVIOUS APPLICATION\n",
    "    prev_SK_ID_CURR = raw_previous_application.loc[raw_previous_application['SK_ID_CURR'] == SK_ID_CURR]\n",
    "    \n",
    "    PREV_application_count = prev_SK_ID_CURR['SK_ID_PREV'].count()\n",
    "    PREV_name_contract_type_count = prev_SK_ID_CURR['NAME_CONTRACT_TYPE'].value_counts().count()\n",
    "    PREV_mean_amount_credit = prev_SK_ID_CURR['AMT_CREDIT'].mean()\n",
    "    PREV_name_contract_status_value_counts = prev_SK_ID_CURR['NAME_CONTRACT_STATUS'].value_counts()\n",
    "    PREV_name_contract_status_approved_count = PREV_name_contract_status_value_counts['Approved'] if 'Approved' in PREV_name_contract_status_value_counts else 0\n",
    "    \n",
    "    \n",
    "    # Add a new row\n",
    "    add_train_credit_application.append([SK_ID_CURR, \n",
    "                                         BUR_credit_active,\n",
    "                                         BUR_credit_closed,\n",
    "                                         BUR_credit_sold,\n",
    "                                         BUR_credit_bad_debt,\n",
    "                                         BUR_sum_credit_day_overdue,\n",
    "                                         BUR_mean_credit_day_overdue,\n",
    "                                         BUR_credit_type_count,\n",
    "                                         BUR_mean_days_credit_update,\n",
    "                                         PREV_application_count,\n",
    "                                         PREV_name_contract_type_count,\n",
    "                                         PREV_mean_amount_credit,\n",
    "                                         PREV_name_contract_status_approved_count,\n",
    "                                        ])\n",
    "    \n",
    "    index = index + 1\n",
    "\n",
    "add_train_credit_application = pd.DataFrame(add_train_credit_application, columns=add_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_test_credit_application = []\n",
    "index = 0\n",
    "for SK_ID_CURR in test_SK_ID_CURR:\n",
    "        if index % 10000 == 0:\n",
    "        print(index, time.time())\n",
    "    \n",
    "    # BUREAU\n",
    "    bureau_SK_ID_CURR = raw_bureau.loc[raw_bureau['SK_ID_CURR'] == SK_ID_CURR]\n",
    "    \n",
    "    credit_active_value_counts = bureau_SK_ID_CURR['CREDIT_ACTIVE'].value_counts()\n",
    "    BUR_credit_active = credit_active_value_counts['Active'] if 'Active' in credit_active_value_counts else 0\n",
    "    BUR_credit_closed = credit_active_value_counts['Closed'] if 'Closed' in credit_active_value_counts else 0\n",
    "    BUR_credit_sold = credit_active_value_counts['Sold'] if 'Sold' in credit_active_value_counts else 0\n",
    "    BUR_credit_bad_debt = credit_active_value_counts['Bad Debt'] if 'Bad Debt' in credit_active_value_counts else 0\n",
    "    \n",
    "    BUR_sum_credit_day_overdue = bureau_SK_ID_CURR['CREDIT_DAY_OVERDUE'].sum()\n",
    "    BUR_mean_credit_day_overdue = bureau_SK_ID_CURR['CREDIT_DAY_OVERDUE'].mean()\n",
    "    \n",
    "    BUR_credit_type_count = bureau_SK_ID_CURR['CREDIT_TYPE'].value_counts().count()\n",
    "    \n",
    "    BUR_mean_days_credit_update = bureau_SK_ID_CURR['DAYS_CREDIT_UPDATE'].mean()\n",
    "    \n",
    "    \n",
    "    # PREVIOUS APPLICATION\n",
    "    prev_SK_ID_CURR = raw_previous_application.loc[raw_previous_application['SK_ID_CURR'] == SK_ID_CURR]\n",
    "    \n",
    "    PREV_application_count = prev_SK_ID_CURR['SK_ID_PREV'].count()\n",
    "    PREV_name_contract_type_count = prev_SK_ID_CURR['NAME_CONTRACT_TYPE'].value_counts().count()\n",
    "    PREV_mean_amount_credit = prev_SK_ID_CURR['AMT_CREDIT'].mean()\n",
    "    PREV_name_contract_status_value_counts = prev_SK_ID_CURR['NAME_CONTRACT_STATUS'].value_counts()\n",
    "    PREV_name_contract_status_approved_count = PREV_name_contract_status_value_counts['Approved'] if 'Approved' in PREV_name_contract_status_value_counts else 0\n",
    "    \n",
    "    \n",
    "    # Add a new row\n",
    "    add_test_credit_application.append([SK_ID_CURR, \n",
    "                                         BUR_credit_active,\n",
    "                                         BUR_credit_closed,\n",
    "                                         BUR_credit_sold,\n",
    "                                         BUR_credit_bad_debt,\n",
    "                                         BUR_sum_credit_day_overdue,\n",
    "                                         BUR_mean_credit_day_overdue,\n",
    "                                         BUR_credit_type_count,\n",
    "                                         BUR_mean_days_credit_update,\n",
    "                                         PREV_application_count,\n",
    "                                         PREV_name_contract_type_count,\n",
    "                                         PREV_mean_amount_credit,\n",
    "                                         PREV_name_contract_status_approved_count,\n",
    "                                        ])\n",
    "    \n",
    "    index = index + 1\n",
    "    \n",
    "add_test_credit_application = pd.DataFrame(add_test_credit_application, columns=add_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_credit_application_1 = pd.merge(left=raw_train_credit_application, right=add_train_credit_application, left_on='SK_ID_CURR', right_on='SK_ID_CURR', how='outer')\n",
    "test_credit_application_1 = pd.merge(left=raw_test_credit_application, right=add_test_credit_application, left_on='SK_ID_CURR', right_on='SK_ID_CURR', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_credit_application_1.to_pickle('train_credit_application_1')\n",
    "test_credit_application_1.to_pickle('test_credit_application_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = list(set(train_credit_application_1.columns.values.tolist()) - set(['SK_ID_CURR', 'TARGET']))\n",
    "\n",
    "non_features = ['SK_ID_CURR', 'TARGET']\n",
    "\n",
    "categorical_features = ['NAME_CONTRACT_TYPE', 'NAME_TYPE_SUITE', 'NAME_INCOME_TYPE', \n",
    "                        'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', \n",
    "                        'OCCUPATION_TYPE', 'WEEKDAY_APPR_PROCESS_START', 'ORGANIZATION_TYPE', \n",
    "                        'FONDKAPREMONT_MODE', 'HOUSETYPE_MODE', 'WALLSMATERIAL_MODE', \n",
    "                        'EMERGENCYSTATE_MODE',\n",
    "                       ]\n",
    "\n",
    "flag_features = ['CODE_GENDER', \n",
    "                 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'FLAG_MOBIL', 'FLAG_EMP_PHONE', \n",
    "                 'FLAG_WORK_PHONE', 'FLAG_CONT_MOBILE', 'FLAG_PHONE', 'FLAG_EMAIL', \n",
    "                 'FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_3', 'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5', \n",
    "                 'FLAG_DOCUMENT_6', 'FLAG_DOCUMENT_7', 'FLAG_DOCUMENT_8', 'FLAG_DOCUMENT_9', \n",
    "                 'FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_12', 'FLAG_DOCUMENT_13', \n",
    "                 'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_15', 'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17', \n",
    "                 'FLAG_DOCUMENT_18', 'FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_20', 'FLAG_DOCUMENT_21',\n",
    "                 'REG_REGION_NOT_LIVE_REGIONREG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION', \n",
    "                 'LIVE_REGION_NOT_WORK_REGION', 'REG_CITY_NOT_LIVE_CITY', 'REG_CITY_NOT_WORK_CITY', \n",
    "                 'LIVE_CITY_NOT_WORK_CITY',\n",
    "                ]\n",
    "\n",
    "numerical_features = list(set(all_features) - set(non_features) - set(categorical_features) - set(flag_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_credit_application_1 = pd.read_pickle('train_credit_application_1')\n",
    "test_credit_application_1 = pd.read_pickle('test_credit_application_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>NAME_TYPE_SUITE</th>\n",
       "      <th>NAME_INCOME_TYPE</th>\n",
       "      <th>NAME_EDUCATION_TYPE</th>\n",
       "      <th>NAME_FAMILY_STATUS</th>\n",
       "      <th>NAME_HOUSING_TYPE</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>DAYS_ID_PUBLISH</th>\n",
       "      <th>OWN_CAR_AGE</th>\n",
       "      <th>FLAG_MOBIL</th>\n",
       "      <th>FLAG_EMP_PHONE</th>\n",
       "      <th>FLAG_WORK_PHONE</th>\n",
       "      <th>FLAG_CONT_MOBILE</th>\n",
       "      <th>FLAG_PHONE</th>\n",
       "      <th>FLAG_EMAIL</th>\n",
       "      <th>OCCUPATION_TYPE</th>\n",
       "      <th>CNT_FAM_MEMBERS</th>\n",
       "      <th>REGION_RATING_CLIENT</th>\n",
       "      <th>REGION_RATING_CLIENT_W_CITY</th>\n",
       "      <th>WEEKDAY_APPR_PROCESS_START</th>\n",
       "      <th>HOUR_APPR_PROCESS_START</th>\n",
       "      <th>REG_REGION_NOT_LIVE_REGION</th>\n",
       "      <th>REG_REGION_NOT_WORK_REGION</th>\n",
       "      <th>LIVE_REGION_NOT_WORK_REGION</th>\n",
       "      <th>REG_CITY_NOT_LIVE_CITY</th>\n",
       "      <th>REG_CITY_NOT_WORK_CITY</th>\n",
       "      <th>LIVE_CITY_NOT_WORK_CITY</th>\n",
       "      <th>ORGANIZATION_TYPE</th>\n",
       "      <th>EXT_SOURCE_1</th>\n",
       "      <th>EXT_SOURCE_2</th>\n",
       "      <th>EXT_SOURCE_3</th>\n",
       "      <th>APARTMENTS_AVG</th>\n",
       "      <th>BASEMENTAREA_AVG</th>\n",
       "      <th>YEARS_BEGINEXPLUATATION_AVG</th>\n",
       "      <th>YEARS_BUILD_AVG</th>\n",
       "      <th>COMMONAREA_AVG</th>\n",
       "      <th>ELEVATORS_AVG</th>\n",
       "      <th>ENTRANCES_AVG</th>\n",
       "      <th>FLOORSMAX_AVG</th>\n",
       "      <th>FLOORSMIN_AVG</th>\n",
       "      <th>LANDAREA_AVG</th>\n",
       "      <th>LIVINGAPARTMENTS_AVG</th>\n",
       "      <th>LIVINGAREA_AVG</th>\n",
       "      <th>NONLIVINGAPARTMENTS_AVG</th>\n",
       "      <th>NONLIVINGAREA_AVG</th>\n",
       "      <th>APARTMENTS_MODE</th>\n",
       "      <th>BASEMENTAREA_MODE</th>\n",
       "      <th>YEARS_BEGINEXPLUATATION_MODE</th>\n",
       "      <th>YEARS_BUILD_MODE</th>\n",
       "      <th>COMMONAREA_MODE</th>\n",
       "      <th>ELEVATORS_MODE</th>\n",
       "      <th>ENTRANCES_MODE</th>\n",
       "      <th>FLOORSMAX_MODE</th>\n",
       "      <th>FLOORSMIN_MODE</th>\n",
       "      <th>LANDAREA_MODE</th>\n",
       "      <th>LIVINGAPARTMENTS_MODE</th>\n",
       "      <th>LIVINGAREA_MODE</th>\n",
       "      <th>NONLIVINGAPARTMENTS_MODE</th>\n",
       "      <th>NONLIVINGAREA_MODE</th>\n",
       "      <th>APARTMENTS_MEDI</th>\n",
       "      <th>BASEMENTAREA_MEDI</th>\n",
       "      <th>YEARS_BEGINEXPLUATATION_MEDI</th>\n",
       "      <th>YEARS_BUILD_MEDI</th>\n",
       "      <th>COMMONAREA_MEDI</th>\n",
       "      <th>ELEVATORS_MEDI</th>\n",
       "      <th>ENTRANCES_MEDI</th>\n",
       "      <th>FLOORSMAX_MEDI</th>\n",
       "      <th>FLOORSMIN_MEDI</th>\n",
       "      <th>LANDAREA_MEDI</th>\n",
       "      <th>LIVINGAPARTMENTS_MEDI</th>\n",
       "      <th>LIVINGAREA_MEDI</th>\n",
       "      <th>NONLIVINGAPARTMENTS_MEDI</th>\n",
       "      <th>NONLIVINGAREA_MEDI</th>\n",
       "      <th>FONDKAPREMONT_MODE</th>\n",
       "      <th>HOUSETYPE_MODE</th>\n",
       "      <th>TOTALAREA_MODE</th>\n",
       "      <th>WALLSMATERIAL_MODE</th>\n",
       "      <th>EMERGENCYSTATE_MODE</th>\n",
       "      <th>OBS_30_CNT_SOCIAL_CIRCLE</th>\n",
       "      <th>DEF_30_CNT_SOCIAL_CIRCLE</th>\n",
       "      <th>OBS_60_CNT_SOCIAL_CIRCLE</th>\n",
       "      <th>DEF_60_CNT_SOCIAL_CIRCLE</th>\n",
       "      <th>DAYS_LAST_PHONE_CHANGE</th>\n",
       "      <th>FLAG_DOCUMENT_2</th>\n",
       "      <th>FLAG_DOCUMENT_3</th>\n",
       "      <th>FLAG_DOCUMENT_4</th>\n",
       "      <th>FLAG_DOCUMENT_5</th>\n",
       "      <th>FLAG_DOCUMENT_6</th>\n",
       "      <th>FLAG_DOCUMENT_7</th>\n",
       "      <th>FLAG_DOCUMENT_8</th>\n",
       "      <th>FLAG_DOCUMENT_9</th>\n",
       "      <th>FLAG_DOCUMENT_10</th>\n",
       "      <th>FLAG_DOCUMENT_11</th>\n",
       "      <th>FLAG_DOCUMENT_12</th>\n",
       "      <th>FLAG_DOCUMENT_13</th>\n",
       "      <th>FLAG_DOCUMENT_14</th>\n",
       "      <th>FLAG_DOCUMENT_15</th>\n",
       "      <th>FLAG_DOCUMENT_16</th>\n",
       "      <th>FLAG_DOCUMENT_17</th>\n",
       "      <th>FLAG_DOCUMENT_18</th>\n",
       "      <th>FLAG_DOCUMENT_19</th>\n",
       "      <th>FLAG_DOCUMENT_20</th>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "      <th>BUR_credit_active</th>\n",
       "      <th>BUR_credit_closed</th>\n",
       "      <th>BUR_credit_sold</th>\n",
       "      <th>BUR_credit_bad_debt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>351000.0</td>\n",
       "      <td>Unaccompanied</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>0.018801</td>\n",
       "      <td>-9461</td>\n",
       "      <td>-637</td>\n",
       "      <td>-3648.0</td>\n",
       "      <td>-2120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Laborers</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>WEDNESDAY</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Business Entity Type 3</td>\n",
       "      <td>0.083037</td>\n",
       "      <td>0.262949</td>\n",
       "      <td>0.139376</td>\n",
       "      <td>0.0247</td>\n",
       "      <td>0.0369</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>0.6192</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0690</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.0369</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0383</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>0.6341</td>\n",
       "      <td>0.0144</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0690</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.0377</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0369</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>0.6243</td>\n",
       "      <td>0.0144</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0690</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>reg oper account</td>\n",
       "      <td>block of flats</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>Stone, brick</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1134.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>1129500.0</td>\n",
       "      <td>Family</td>\n",
       "      <td>State servant</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>0.003541</td>\n",
       "      <td>-16765</td>\n",
       "      <td>-1188</td>\n",
       "      <td>-1186.0</td>\n",
       "      <td>-291</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Core staff</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MONDAY</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>School</td>\n",
       "      <td>0.311267</td>\n",
       "      <td>0.622246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0959</td>\n",
       "      <td>0.0529</td>\n",
       "      <td>0.9851</td>\n",
       "      <td>0.7960</td>\n",
       "      <td>0.0605</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.2917</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0773</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0924</td>\n",
       "      <td>0.0538</td>\n",
       "      <td>0.9851</td>\n",
       "      <td>0.8040</td>\n",
       "      <td>0.0497</td>\n",
       "      <td>0.0806</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.2917</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.0554</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0968</td>\n",
       "      <td>0.0529</td>\n",
       "      <td>0.9851</td>\n",
       "      <td>0.7987</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.2917</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0787</td>\n",
       "      <td>0.0558</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.01</td>\n",
       "      <td>reg oper account</td>\n",
       "      <td>block of flats</td>\n",
       "      <td>0.0714</td>\n",
       "      <td>Block</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-828.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100004</td>\n",
       "      <td>0</td>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>Unaccompanied</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>0.010032</td>\n",
       "      <td>-19046</td>\n",
       "      <td>-225</td>\n",
       "      <td>-4260.0</td>\n",
       "      <td>-2531</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Laborers</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>MONDAY</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Government</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.555912</td>\n",
       "      <td>0.729567</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-815.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100006</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>297000.0</td>\n",
       "      <td>Unaccompanied</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>0.008019</td>\n",
       "      <td>-19005</td>\n",
       "      <td>-3039</td>\n",
       "      <td>-9833.0</td>\n",
       "      <td>-2437</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Laborers</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>WEDNESDAY</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Business Entity Type 3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650442</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-617.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100007</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>Unaccompanied</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>0.028663</td>\n",
       "      <td>-19932</td>\n",
       "      <td>-3038</td>\n",
       "      <td>-4311.0</td>\n",
       "      <td>-3458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Core staff</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>THURSDAY</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Religion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.322738</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1106.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
       "0      100002       1         Cash loans           M            N   \n",
       "1      100003       0         Cash loans           F            N   \n",
       "2      100004       0    Revolving loans           M            Y   \n",
       "3      100006       0         Cash loans           F            N   \n",
       "4      100007       0         Cash loans           M            N   \n",
       "\n",
       "  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "0               Y             0          202500.0    406597.5      24700.5   \n",
       "1               N             0          270000.0   1293502.5      35698.5   \n",
       "2               Y             0           67500.0    135000.0       6750.0   \n",
       "3               Y             0          135000.0    312682.5      29686.5   \n",
       "4               Y             0          121500.0    513000.0      21865.5   \n",
       "\n",
       "   AMT_GOODS_PRICE NAME_TYPE_SUITE NAME_INCOME_TYPE  \\\n",
       "0         351000.0   Unaccompanied          Working   \n",
       "1        1129500.0          Family    State servant   \n",
       "2         135000.0   Unaccompanied          Working   \n",
       "3         297000.0   Unaccompanied          Working   \n",
       "4         513000.0   Unaccompanied          Working   \n",
       "\n",
       "             NAME_EDUCATION_TYPE    NAME_FAMILY_STATUS  NAME_HOUSING_TYPE  \\\n",
       "0  Secondary / secondary special  Single / not married  House / apartment   \n",
       "1               Higher education               Married  House / apartment   \n",
       "2  Secondary / secondary special  Single / not married  House / apartment   \n",
       "3  Secondary / secondary special        Civil marriage  House / apartment   \n",
       "4  Secondary / secondary special  Single / not married  House / apartment   \n",
       "\n",
       "   REGION_POPULATION_RELATIVE  DAYS_BIRTH  DAYS_EMPLOYED  DAYS_REGISTRATION  \\\n",
       "0                    0.018801       -9461           -637            -3648.0   \n",
       "1                    0.003541      -16765          -1188            -1186.0   \n",
       "2                    0.010032      -19046           -225            -4260.0   \n",
       "3                    0.008019      -19005          -3039            -9833.0   \n",
       "4                    0.028663      -19932          -3038            -4311.0   \n",
       "\n",
       "   DAYS_ID_PUBLISH  OWN_CAR_AGE  FLAG_MOBIL  FLAG_EMP_PHONE  FLAG_WORK_PHONE  \\\n",
       "0            -2120          NaN           1               1                0   \n",
       "1             -291          NaN           1               1                0   \n",
       "2            -2531         26.0           1               1                1   \n",
       "3            -2437          NaN           1               1                0   \n",
       "4            -3458          NaN           1               1                0   \n",
       "\n",
       "   FLAG_CONT_MOBILE  FLAG_PHONE  FLAG_EMAIL OCCUPATION_TYPE  CNT_FAM_MEMBERS  \\\n",
       "0                 1           1           0        Laborers              1.0   \n",
       "1                 1           1           0      Core staff              2.0   \n",
       "2                 1           1           0        Laborers              1.0   \n",
       "3                 1           0           0        Laborers              2.0   \n",
       "4                 1           0           0      Core staff              1.0   \n",
       "\n",
       "   REGION_RATING_CLIENT  REGION_RATING_CLIENT_W_CITY  \\\n",
       "0                     2                            2   \n",
       "1                     1                            1   \n",
       "2                     2                            2   \n",
       "3                     2                            2   \n",
       "4                     2                            2   \n",
       "\n",
       "  WEEKDAY_APPR_PROCESS_START  HOUR_APPR_PROCESS_START  \\\n",
       "0                  WEDNESDAY                       10   \n",
       "1                     MONDAY                       11   \n",
       "2                     MONDAY                        9   \n",
       "3                  WEDNESDAY                       17   \n",
       "4                   THURSDAY                       11   \n",
       "\n",
       "   REG_REGION_NOT_LIVE_REGION  REG_REGION_NOT_WORK_REGION  \\\n",
       "0                           0                           0   \n",
       "1                           0                           0   \n",
       "2                           0                           0   \n",
       "3                           0                           0   \n",
       "4                           0                           0   \n",
       "\n",
       "   LIVE_REGION_NOT_WORK_REGION  REG_CITY_NOT_LIVE_CITY  \\\n",
       "0                            0                       0   \n",
       "1                            0                       0   \n",
       "2                            0                       0   \n",
       "3                            0                       0   \n",
       "4                            0                       0   \n",
       "\n",
       "   REG_CITY_NOT_WORK_CITY  LIVE_CITY_NOT_WORK_CITY       ORGANIZATION_TYPE  \\\n",
       "0                       0                        0  Business Entity Type 3   \n",
       "1                       0                        0                  School   \n",
       "2                       0                        0              Government   \n",
       "3                       0                        0  Business Entity Type 3   \n",
       "4                       1                        1                Religion   \n",
       "\n",
       "   EXT_SOURCE_1  EXT_SOURCE_2  EXT_SOURCE_3  APARTMENTS_AVG  BASEMENTAREA_AVG  \\\n",
       "0      0.083037      0.262949      0.139376          0.0247            0.0369   \n",
       "1      0.311267      0.622246           NaN          0.0959            0.0529   \n",
       "2           NaN      0.555912      0.729567             NaN               NaN   \n",
       "3           NaN      0.650442           NaN             NaN               NaN   \n",
       "4           NaN      0.322738           NaN             NaN               NaN   \n",
       "\n",
       "   YEARS_BEGINEXPLUATATION_AVG  YEARS_BUILD_AVG  COMMONAREA_AVG  \\\n",
       "0                       0.9722           0.6192          0.0143   \n",
       "1                       0.9851           0.7960          0.0605   \n",
       "2                          NaN              NaN             NaN   \n",
       "3                          NaN              NaN             NaN   \n",
       "4                          NaN              NaN             NaN   \n",
       "\n",
       "   ELEVATORS_AVG  ENTRANCES_AVG  FLOORSMAX_AVG  FLOORSMIN_AVG  LANDAREA_AVG  \\\n",
       "0           0.00         0.0690         0.0833         0.1250        0.0369   \n",
       "1           0.08         0.0345         0.2917         0.3333        0.0130   \n",
       "2            NaN            NaN            NaN            NaN           NaN   \n",
       "3            NaN            NaN            NaN            NaN           NaN   \n",
       "4            NaN            NaN            NaN            NaN           NaN   \n",
       "\n",
       "   LIVINGAPARTMENTS_AVG  LIVINGAREA_AVG  NONLIVINGAPARTMENTS_AVG  \\\n",
       "0                0.0202          0.0190                   0.0000   \n",
       "1                0.0773          0.0549                   0.0039   \n",
       "2                   NaN             NaN                      NaN   \n",
       "3                   NaN             NaN                      NaN   \n",
       "4                   NaN             NaN                      NaN   \n",
       "\n",
       "   NONLIVINGAREA_AVG  APARTMENTS_MODE  BASEMENTAREA_MODE  \\\n",
       "0             0.0000           0.0252             0.0383   \n",
       "1             0.0098           0.0924             0.0538   \n",
       "2                NaN              NaN                NaN   \n",
       "3                NaN              NaN                NaN   \n",
       "4                NaN              NaN                NaN   \n",
       "\n",
       "   YEARS_BEGINEXPLUATATION_MODE  YEARS_BUILD_MODE  COMMONAREA_MODE  \\\n",
       "0                        0.9722            0.6341           0.0144   \n",
       "1                        0.9851            0.8040           0.0497   \n",
       "2                           NaN               NaN              NaN   \n",
       "3                           NaN               NaN              NaN   \n",
       "4                           NaN               NaN              NaN   \n",
       "\n",
       "   ELEVATORS_MODE  ENTRANCES_MODE  FLOORSMAX_MODE  FLOORSMIN_MODE  \\\n",
       "0          0.0000          0.0690          0.0833          0.1250   \n",
       "1          0.0806          0.0345          0.2917          0.3333   \n",
       "2             NaN             NaN             NaN             NaN   \n",
       "3             NaN             NaN             NaN             NaN   \n",
       "4             NaN             NaN             NaN             NaN   \n",
       "\n",
       "   LANDAREA_MODE  LIVINGAPARTMENTS_MODE  LIVINGAREA_MODE  \\\n",
       "0         0.0377                  0.022           0.0198   \n",
       "1         0.0128                  0.079           0.0554   \n",
       "2            NaN                    NaN              NaN   \n",
       "3            NaN                    NaN              NaN   \n",
       "4            NaN                    NaN              NaN   \n",
       "\n",
       "   NONLIVINGAPARTMENTS_MODE  NONLIVINGAREA_MODE  APARTMENTS_MEDI  \\\n",
       "0                       0.0                 0.0           0.0250   \n",
       "1                       0.0                 0.0           0.0968   \n",
       "2                       NaN                 NaN              NaN   \n",
       "3                       NaN                 NaN              NaN   \n",
       "4                       NaN                 NaN              NaN   \n",
       "\n",
       "   BASEMENTAREA_MEDI  YEARS_BEGINEXPLUATATION_MEDI  YEARS_BUILD_MEDI  \\\n",
       "0             0.0369                        0.9722            0.6243   \n",
       "1             0.0529                        0.9851            0.7987   \n",
       "2                NaN                           NaN               NaN   \n",
       "3                NaN                           NaN               NaN   \n",
       "4                NaN                           NaN               NaN   \n",
       "\n",
       "   COMMONAREA_MEDI  ELEVATORS_MEDI  ENTRANCES_MEDI  FLOORSMAX_MEDI  \\\n",
       "0           0.0144            0.00          0.0690          0.0833   \n",
       "1           0.0608            0.08          0.0345          0.2917   \n",
       "2              NaN             NaN             NaN             NaN   \n",
       "3              NaN             NaN             NaN             NaN   \n",
       "4              NaN             NaN             NaN             NaN   \n",
       "\n",
       "   FLOORSMIN_MEDI  LANDAREA_MEDI  LIVINGAPARTMENTS_MEDI  LIVINGAREA_MEDI  \\\n",
       "0          0.1250         0.0375                 0.0205           0.0193   \n",
       "1          0.3333         0.0132                 0.0787           0.0558   \n",
       "2             NaN            NaN                    NaN              NaN   \n",
       "3             NaN            NaN                    NaN              NaN   \n",
       "4             NaN            NaN                    NaN              NaN   \n",
       "\n",
       "   NONLIVINGAPARTMENTS_MEDI  NONLIVINGAREA_MEDI FONDKAPREMONT_MODE  \\\n",
       "0                    0.0000                0.00   reg oper account   \n",
       "1                    0.0039                0.01   reg oper account   \n",
       "2                       NaN                 NaN                NaN   \n",
       "3                       NaN                 NaN                NaN   \n",
       "4                       NaN                 NaN                NaN   \n",
       "\n",
       "   HOUSETYPE_MODE  TOTALAREA_MODE WALLSMATERIAL_MODE EMERGENCYSTATE_MODE  \\\n",
       "0  block of flats          0.0149       Stone, brick                  No   \n",
       "1  block of flats          0.0714              Block                  No   \n",
       "2             NaN             NaN                NaN                 NaN   \n",
       "3             NaN             NaN                NaN                 NaN   \n",
       "4             NaN             NaN                NaN                 NaN   \n",
       "\n",
       "   OBS_30_CNT_SOCIAL_CIRCLE  DEF_30_CNT_SOCIAL_CIRCLE  \\\n",
       "0                       2.0                       2.0   \n",
       "1                       1.0                       0.0   \n",
       "2                       0.0                       0.0   \n",
       "3                       2.0                       0.0   \n",
       "4                       0.0                       0.0   \n",
       "\n",
       "   OBS_60_CNT_SOCIAL_CIRCLE  DEF_60_CNT_SOCIAL_CIRCLE  DAYS_LAST_PHONE_CHANGE  \\\n",
       "0                       2.0                       2.0                 -1134.0   \n",
       "1                       1.0                       0.0                  -828.0   \n",
       "2                       0.0                       0.0                  -815.0   \n",
       "3                       2.0                       0.0                  -617.0   \n",
       "4                       0.0                       0.0                 -1106.0   \n",
       "\n",
       "   FLAG_DOCUMENT_2  FLAG_DOCUMENT_3  FLAG_DOCUMENT_4  FLAG_DOCUMENT_5  \\\n",
       "0                0                1                0                0   \n",
       "1                0                1                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                1                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   FLAG_DOCUMENT_6  FLAG_DOCUMENT_7  FLAG_DOCUMENT_8  FLAG_DOCUMENT_9  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                1                0   \n",
       "\n",
       "   FLAG_DOCUMENT_10  FLAG_DOCUMENT_11  FLAG_DOCUMENT_12  FLAG_DOCUMENT_13  \\\n",
       "0                 0                 0                 0                 0   \n",
       "1                 0                 0                 0                 0   \n",
       "2                 0                 0                 0                 0   \n",
       "3                 0                 0                 0                 0   \n",
       "4                 0                 0                 0                 0   \n",
       "\n",
       "   FLAG_DOCUMENT_14  FLAG_DOCUMENT_15  FLAG_DOCUMENT_16  FLAG_DOCUMENT_17  \\\n",
       "0                 0                 0                 0                 0   \n",
       "1                 0                 0                 0                 0   \n",
       "2                 0                 0                 0                 0   \n",
       "3                 0                 0                 0                 0   \n",
       "4                 0                 0                 0                 0   \n",
       "\n",
       "   FLAG_DOCUMENT_18  FLAG_DOCUMENT_19  FLAG_DOCUMENT_20  FLAG_DOCUMENT_21  \\\n",
       "0                 0                 0                 0                 0   \n",
       "1                 0                 0                 0                 0   \n",
       "2                 0                 0                 0                 0   \n",
       "3                 0                 0                 0                 0   \n",
       "4                 0                 0                 0                 0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_HOUR  AMT_REQ_CREDIT_BUREAU_DAY  \\\n",
       "0                         0.0                        0.0   \n",
       "1                         0.0                        0.0   \n",
       "2                         0.0                        0.0   \n",
       "3                         NaN                        NaN   \n",
       "4                         0.0                        0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_MON  \\\n",
       "0                         0.0                        0.0   \n",
       "1                         0.0                        0.0   \n",
       "2                         0.0                        0.0   \n",
       "3                         NaN                        NaN   \n",
       "4                         0.0                        0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_QRT  AMT_REQ_CREDIT_BUREAU_YEAR  BUR_credit_active  \\\n",
       "0                        0.0                         1.0                  2   \n",
       "1                        0.0                         0.0                  1   \n",
       "2                        0.0                         0.0                  0   \n",
       "3                        NaN                         NaN                  0   \n",
       "4                        0.0                         0.0                  0   \n",
       "\n",
       "   BUR_credit_closed  BUR_credit_sold  BUR_credit_bad_debt  \n",
       "0                  6                0                    0  \n",
       "1                  3                0                    0  \n",
       "2                  2                0                    0  \n",
       "3                  0                0                    0  \n",
       "4                  1                0                    0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_credit_application_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_data(df, train_df=None):\n",
    "    if df is None:\n",
    "        return None\n",
    "    \n",
    "    new_df = df.copy()\n",
    "    new_train_df = train_df.copy() if train_df is not None else None\n",
    "    \n",
    "    median_comp_df = new_train_df if new_train_df is not None else new_df\n",
    "    for col in new_df.columns.values:\n",
    "        if new_df[col].dtype == np.float or new_df[col].dtype == np.int:\n",
    "            new_df[col] = new_df[col].fillna(median_comp_df[col].median())\n",
    "        elif new_df[col].dtype == np.object:\n",
    "            new_df[col] = new_df[col].fillna(median_comp_df[col].value_counts().idxmax())\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "def handle_outlier(df):\n",
    "    if df is None:\n",
    "        return None\n",
    "    \n",
    "    new_df = df.copy()\n",
    "    \n",
    "    # new_df['SK_ID_CURR'] = new_df['SK_ID_CURR']\n",
    "    # if 'TARGET' in new_df:\n",
    "    #     new_df['TARGET'] = new_df['TARGET']\n",
    "    # new_df['NAME_CONTRACT_TYPE'] = new_df['NAME_CONTRACT_TYPE']\n",
    "    new_df['CODE_GENDER'] = new_df['CODE_GENDER'].apply(lambda val: 1 if val == 'XNA' or val == 'F' else 0)\n",
    "    new_df['FLAG_OWN_CAR'] = new_df['FLAG_OWN_CAR'].apply(lambda val: 1 if val == 'N' else 1)\n",
    "    new_df['FLAG_OWN_REALTY'] = new_df['FLAG_OWN_REALTY'].apply(lambda val: 1 if val == 'N' else 1)\n",
    "    new_df['CNT_CHILDREN'] = new_df['CNT_CHILDREN'].apply(lambda val: 3 if val > 3 else val)\n",
    "    new_df['AMT_INCOME_TOTAL'] = new_df['AMT_INCOME_TOTAL'].apply(lambda val: 500000 if val > 500000 else val)\n",
    "    new_df['AMT_CREDIT'] = new_df['AMT_CREDIT'].apply(lambda val: 1800000 if val > 1800000 else val)\n",
    "    new_df['AMT_ANNUITY'] = new_df['AMT_ANNUITY'].apply(lambda val: 100000 if val > 100000 else val)\n",
    "    new_df['AMT_GOODS_PRICE'] = new_df['AMT_GOODS_PRICE'].apply(lambda val: 2500000 if val > 2500000 else val)\n",
    "    # new_df['NAME_TYPE_SUITE'] = new_df['NAME_TYPE_SUITE']\n",
    "    # new_df['NAME_INCOME_TYPE'] = new_df['NAME_INCOME_TYPE']\n",
    "    # new_df['NAME_EDUCATION_TYPE'] = new_df['NAME_EDUCATION_TYPE']\n",
    "    new_df['NAME_FAMILY_STATUS'] = new_df['NAME_FAMILY_STATUS'].apply(lambda val: 'Married' if val == 'Unknown' else val)\n",
    "    # new_df['NAME_HOUSING_TYPE'] = new_df['NAME_HOUSING_TYPE']\n",
    "    # new_df['REGION_POPULATION_RELATIVE'] = new_df['REGION_POPULATION_RELATIVE']\n",
    "    # new_df['DAYS_BIRTH'] = new_df['DAYS_BIRTH']\n",
    "    new_df['DAYS_EMPLOYED'] = new_df['DAYS_EMPLOYED'].apply(lambda val: 0 if val > 0 else val)\n",
    "    new_df['DAYS_REGISTRATION'] = new_df['DAYS_REGISTRATION'].apply(lambda val: -18000 if val < -18000 else val)\n",
    "    new_df['DAYS_ID_PUBLISH'] = new_df['DAYS_ID_PUBLISH'].apply(lambda val: -6300 if val < -6300 else val)\n",
    "    new_df['OWN_CAR_AGE'] = new_df['OWN_CAR_AGE'].apply(lambda val: 65 if val > 65 else val)\n",
    "    # new_df['FLAG_MOBIL'] = new_df['FLAG_MOBIL']\n",
    "    # new_df['FLAG_EMP_PHONE'] = new_df['FLAG_EMP_PHONE']\n",
    "    # new_df['FLAG_WORK_PHONE'] = new_df['FLAG_WORK_PHONE']\n",
    "    # new_df['FLAG_CONT_MOBILE'] = new_df['FLAG_CONT_MOBILE']\n",
    "    # new_df['FLAG_PHONE'] = new_df['FLAG_PHONE']\n",
    "    # new_df['FLAG_EMAIL'] = new_df['FLAG_EMAIL']\n",
    "    # new_df['OCCUPATION_TYPE'] = new_df['OCCUPATION_TYPE']\n",
    "    # new_df['CNT_FAM_MEMBERS'] = new_df['CNT_FAM_MEMBERS']\n",
    "    # new_df['REGION_RATING_CLIENT'] = new_df['REGION_RATING_CLIENT']\n",
    "    # new_df['REGION_RATING_CLIENT_W_CITY'] = new_df['REGION_RATING_CLIENT_W_CITY']\n",
    "    # new_df['WEEKDAY_APPR_PROCESS_START'] = new_df['WEEKDAY_APPR_PROCESS_START']\n",
    "    # new_df['HOUR_APPR_PROCESS_START'] = new_df['HOUR_APPR_PROCESS_START']\n",
    "    # new_df['REG_REGION_NOT_LIVE_REGION'] = new_df['REG_REGION_NOT_LIVE_REGION']\n",
    "    # new_df['REG_REGION_NOT_WORK_REGION'] = new_df['REG_REGION_NOT_WORK_REGION']\n",
    "    # new_df['LIVE_REGION_NOT_WORK_REGION'] = new_df['LIVE_REGION_NOT_WORK_REGION']\n",
    "    # new_df['REG_CITY_NOT_LIVE_CITY'] = new_df['REG_CITY_NOT_LIVE_CITY']\n",
    "    # new_df['REG_CITY_NOT_WORK_CITY'] = new_df['REG_CITY_NOT_WORK_CITY']\n",
    "    # new_df['LIVE_CITY_NOT_WORK_CITY'] = new_df['LIVE_CITY_NOT_WORK_CITY']\n",
    "    new_df['ORGANIZATION_TYPE'] = new_df['ORGANIZATION_TYPE'].apply(lambda val: 'Unknown' if val == 'XNA' else val)\n",
    "    # new_df['EXT_SOURCE_1'] = new_df['EXT_SOURCE_1']\n",
    "    # new_df['EXT_SOURCE_2'] = new_df['EXT_SOURCE_2']\n",
    "    # new_df['EXT_SOURCE_3'] = new_df['EXT_SOURCE_3']\n",
    "    # new_df['APARTMENTS_AVG'] = new_df['APARTMENTS_AVG']\n",
    "    new_df['BASEMENTAREA_AVG'] = new_df['BASEMENTAREA_AVG'].apply(lambda val: 0.5 if val > 0.5 else val)\n",
    "    new_df['YEARS_BEGINEXPLUATATION_AVG'] = new_df['YEARS_BEGINEXPLUATATION_AVG'].apply(lambda val: 0.9 if val < 0.9 else val)\n",
    "    # new_df['YEARS_BUILD_AVG'] = new_df['YEARS_BUILD_AVG']\n",
    "    new_df['COMMONAREA_AVG'] = new_df['COMMONAREA_AVG'].apply(lambda val: 0.4 if val > 0.4 else val)\n",
    "    new_df['ELEVATORS_AVG'] = new_df['ELEVATORS_AVG'].apply(lambda val: 0.4 if val > 0.4 else val)\n",
    "    new_df['ENTRANCES_AVG'] = new_df['ENTRANCES_AVG'].apply(lambda val: 0.5 if val > 0.5 else val)\n",
    "    # new_df['FLOORSMAX_AVG'] = new_df['FLOORSMAX_AVG']\n",
    "    # new_df['FLOORSMIN_AVG'] = new_df['FLOORSMIN_AVG']\n",
    "    new_df['LANDAREA_AVG'] = new_df['LANDAREA_AVG'].apply(lambda val: 0.4 if val > 0.4 else val)\n",
    "    new_df['LIVINGAPARTMENTS_AVG'] = new_df['LIVINGAPARTMENTS_AVG'].apply(lambda val: 0.6 if val > 0.6 else val)\n",
    "    new_df['LIVINGAREA_AVG'] = new_df['LIVINGAREA_AVG'].apply(lambda val: 0.75 if val > 0.75 else val)\n",
    "    new_df['NONLIVINGAPARTMENTS_AVG'] = new_df['NONLIVINGAPARTMENTS_AVG'].apply(lambda val: 0.075 if val > 0.075 else val)\n",
    "    new_df['NONLIVINGAREA_AVG'] = new_df['NONLIVINGAREA_AVG'].apply(lambda val: 0.3 if val > 0.3 else val)\n",
    "    new_df['APARTMENTS_MODE'] = new_df['APARTMENTS_MODE'].apply(lambda val: 0.6 if val > 0.6 else val)\n",
    "    new_df['BASEMENTAREA_MODE'] = new_df['BASEMENTAREA_MODE'].apply(lambda val: 0.4 if val > 0.4 else val)\n",
    "    new_df['YEARS_BEGINEXPLUATATION_MODE'] = new_df['YEARS_BEGINEXPLUATATION_MODE'].apply(lambda val: 0.95 if val < 0.95 else val)\n",
    "    new_df['YEARS_BUILD_MODE'] = new_df['YEARS_BUILD_MODE'].apply(lambda val: 0.3 if val < 0.3 else val)\n",
    "    new_df['COMMONAREA_MODE'] = new_df['COMMONAREA_MODE'].apply(lambda val: 0.25 if val > 0.25 else val)\n",
    "    new_df['ELEVATORS_MODE'] = new_df['ELEVATORS_MODE'].apply(lambda val: 0.4 if val > 0.4 else val)\n",
    "    new_df['ENTRANCES_MODE'] = new_df['ENTRANCES_MODE'].apply(lambda val: 0.4 if val > 0.4 else val)\n",
    "    new_df['FLOORSMAX_MODE'] = new_df['FLOORSMAX_MODE'].apply(lambda val: 0.6 if val > 0.6 else val)\n",
    "    new_df['FLOORSMIN_MODE'] = new_df['FLOORSMIN_MODE'].apply(lambda val: 0.6 if val > 0.6 else val)\n",
    "    new_df['LANDAREA_MODE'] = new_df['LANDAREA_MODE'].apply(lambda val: 0.4 if val > 0.4 else val)\n",
    "    new_df['LIVINGAPARTMENTS_MODE'] = new_df['LIVINGAPARTMENTS_MODE'].apply(lambda val: 0.6 if val > 0.6 else val)\n",
    "    new_df['LIVINGAREA_MODE'] = new_df['LIVINGAREA_MODE'].apply(lambda val: 0.75 if val > 0.75 else val)\n",
    "    new_df['NONLIVINGAPARTMENTS_MODE'] = new_df['NONLIVINGAPARTMENTS_MODE'].apply(lambda val: 0.075 if val > 0.075 else val)\n",
    "    new_df['NONLIVINGAREA_MODE'] = new_df['NONLIVINGAREA_MODE'].apply(lambda val: 0.2 if val > 0.2 else val)\n",
    "    new_df['APARTMENTS_MEDI'] = new_df['APARTMENTS_MEDI'].apply(lambda val: 0.6 if val > 0.6 else val)\n",
    "    new_df['BASEMENTAREA_MEDI'] = new_df['BASEMENTAREA_MEDI'].apply(lambda val: 0.4 if val > 0.4 else val)\n",
    "    new_df['YEARS_BEGINEXPLUATATION_MEDI'] = new_df['YEARS_BEGINEXPLUATATION_MEDI'].apply(lambda val: 0.95 if val < 0.95 else val)\n",
    "    new_df['YEARS_BUILD_MEDI'] = new_df['YEARS_BUILD_MEDI'].apply(lambda val: 0.3 if val < 0.3 else val)\n",
    "    new_df['COMMONAREA_MEDI'] = new_df['COMMONAREA_MEDI'].apply(lambda val: 0.25 if val > 0.25 else val)\n",
    "    new_df['ELEVATORS_MEDI'] = new_df['ELEVATORS_MEDI'].apply(lambda val: 0.4 if val > 0.4 else val)\n",
    "    new_df['ENTRANCES_MEDI'] = new_df['ENTRANCES_MEDI'].apply(lambda val: 0.4 if val > 0.4 else val)\n",
    "    new_df['FLOORSMAX_MEDI'] = new_df['FLOORSMAX_MEDI'].apply(lambda val: 0.6 if val > 0.6 else val)\n",
    "    new_df['FLOORSMIN_MEDI'] = new_df['FLOORSMIN_MEDI'].apply(lambda val: 0.6 if val > 0.6 else val)\n",
    "    new_df['LANDAREA_MEDI'] = new_df['LANDAREA_MEDI'].apply(lambda val: 0.4 if val > 0.4 else val)\n",
    "    new_df['LIVINGAPARTMENTS_MEDI'] = new_df['LIVINGAPARTMENTS_MEDI'].apply(lambda val: 0.6 if val > 0.6 else val)\n",
    "    new_df['LIVINGAREA_MEDI'] = new_df['LIVINGAREA_MEDI'].apply(lambda val: 0.75 if val > 0.75 else val)\n",
    "    new_df['NONLIVINGAPARTMENTS_MEDI'] = new_df['NONLIVINGAPARTMENTS_MEDI'].apply(lambda val: 0.075 if val > 0.075 else val)\n",
    "    new_df['NONLIVINGAREA_MEDI'] = new_df['NONLIVINGAREA_MEDI'].apply(lambda val: 0.2 if val > 0.2 else val)\n",
    "    # new_df['FONDKAPREMONT_MODE'] = new_df['FONDKAPREMONT_MODE']\n",
    "    # new_df['HOUSETYPE_MODE'] = new_df['HOUSETYPE_MODE']\n",
    "    new_df['TOTALAREA_MODE'] = new_df['TOTALAREA_MODE'].apply(lambda val: 0.60 if val > 0.60 else val)\n",
    "    # new_df['WALLSMATERIAL_MODE'] = new_df['WALLSMATERIAL_MODE']\n",
    "    # new_df['EMERGENCYSTATE_MODE'] = new_df['EMERGENCYSTATE_MODE']\n",
    "    new_df['OBS_30_CNT_SOCIAL_CIRCLE'] = new_df['OBS_30_CNT_SOCIAL_CIRCLE'].apply(lambda val: 25 if val > 25 else val)\n",
    "    new_df['DEF_30_CNT_SOCIAL_CIRCLE'] = new_df['DEF_30_CNT_SOCIAL_CIRCLE'].apply(lambda val: 5 if val > 5 else val)\n",
    "    new_df['OBS_60_CNT_SOCIAL_CIRCLE'] = new_df['OBS_60_CNT_SOCIAL_CIRCLE'].apply(lambda val: 15 if val > 15 else val)\n",
    "    new_df['DEF_60_CNT_SOCIAL_CIRCLE'] = new_df['DEF_60_CNT_SOCIAL_CIRCLE'].apply(lambda val: 3 if val > 3 else val)\n",
    "    new_df['DAYS_LAST_PHONE_CHANGE'] = new_df['DAYS_LAST_PHONE_CHANGE'].apply(lambda val: -3200 if val < -3200 else val)\n",
    "    # new_df['FLAG_DOCUMENT_2'] = new_df['FLAG_DOCUMENT_2']\n",
    "    # new_df['FLAG_DOCUMENT_3'] = new_df['FLAG_DOCUMENT_3']\n",
    "    # new_df['FLAG_DOCUMENT_4'] = new_df['FLAG_DOCUMENT_4']\n",
    "    # new_df['FLAG_DOCUMENT_5'] = new_df['FLAG_DOCUMENT_5']\n",
    "    # new_df['FLAG_DOCUMENT_6'] = new_df['FLAG_DOCUMENT_6']\n",
    "    # new_df['FLAG_DOCUMENT_7'] = new_df['FLAG_DOCUMENT_7']\n",
    "    # new_df['FLAG_DOCUMENT_8'] = new_df['FLAG_DOCUMENT_8']\n",
    "    # new_df['FLAG_DOCUMENT_9'] = new_df['FLAG_DOCUMENT_9']\n",
    "    # new_df['FLAG_DOCUMENT_10'] = new_df['FLAG_DOCUMENT_10']\n",
    "    # new_df['FLAG_DOCUMENT_11'] = new_df['FLAG_DOCUMENT_11']\n",
    "    # new_df['FLAG_DOCUMENT_12'] = new_df['FLAG_DOCUMENT_12']\n",
    "    # new_df['FLAG_DOCUMENT_13'] = new_df['FLAG_DOCUMENT_13']\n",
    "    # new_df['FLAG_DOCUMENT_14'] = new_df['FLAG_DOCUMENT_14']\n",
    "    # new_df['FLAG_DOCUMENT_15'] = new_df['FLAG_DOCUMENT_15']\n",
    "    # new_df['FLAG_DOCUMENT_16'] = new_df['FLAG_DOCUMENT_16']\n",
    "    # new_df['FLAG_DOCUMENT_17'] = new_df['FLAG_DOCUMENT_17']\n",
    "    # new_df['FLAG_DOCUMENT_18'] = new_df['FLAG_DOCUMENT_18']\n",
    "    # new_df['FLAG_DOCUMENT_19'] = new_df['FLAG_DOCUMENT_19']\n",
    "    # new_df['FLAG_DOCUMENT_20'] = new_df['FLAG_DOCUMENT_20']\n",
    "    # new_df['FLAG_DOCUMENT_21'] = new_df['FLAG_DOCUMENT_21']\n",
    "    new_df['AMT_REQ_CREDIT_BUREAU_HOUR'] = new_df['AMT_REQ_CREDIT_BUREAU_HOUR'].apply(lambda val: 2.0 if val > 2.0 else val)\n",
    "    new_df['AMT_REQ_CREDIT_BUREAU_DAY'] = new_df['AMT_REQ_CREDIT_BUREAU_DAY'].apply(lambda val: 4.0 if val > 4.0 else val)\n",
    "    new_df['AMT_REQ_CREDIT_BUREAU_WEEK'] = new_df['AMT_REQ_CREDIT_BUREAU_WEEK'].apply(lambda val: 3.0 if val > 3.0 else val)\n",
    "    new_df['AMT_REQ_CREDIT_BUREAU_MON'] = new_df['AMT_REQ_CREDIT_BUREAU_MON'].apply(lambda val: 17.0 if val > 17.0 else val)\n",
    "    new_df['AMT_REQ_CREDIT_BUREAU_QRT'] = new_df['AMT_REQ_CREDIT_BUREAU_QRT'].apply(lambda val: 6.0 if val > 6.0 else val)\n",
    "    new_df['AMT_REQ_CREDIT_BUREAU_YEAR'] = new_df['AMT_REQ_CREDIT_BUREAU_YEAR'].apply(lambda val: 14.0 if val > 14.0 else val)\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "def clean_data(df, train_df=None):  \n",
    "    if df is None:\n",
    "        return None\n",
    "    \n",
    "    new_df = df.copy()\n",
    "    new_train_df = train_df.copy() if train_df is not None else None\n",
    "    \n",
    "    # Missing Values\n",
    "    new_df = fill_missing_data(new_df, new_train_df)\n",
    "    new_train_df = fill_missing_data(new_train_df) if new_train_df is not None else None\n",
    "    \n",
    "    # Handling Outliers\n",
    "    new_df = handle_outlier(new_df)\n",
    "    new_train_df = handle_outlier(new_train_df) if new_train_df is not None else None\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "complete_train_credit_application = clean_data(df=train_credit_application_1)\n",
    "complete_test_credit_application = clean_data(df=test_credit_application_1, train_df=train_credit_application_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_feature(df, train_df=None):\n",
    "    if df is None:\n",
    "        return None\n",
    "    \n",
    "    new_df = df.copy()\n",
    "    if train_df is not None:\n",
    "        new_train_df = train_df.copy()\n",
    "    else:\n",
    "        new_train_df = None\n",
    "\n",
    "    # Dimensionality Reduction - Numerical Features\n",
    "    lda = discriminant_analysis.LinearDiscriminantAnalysis(n_components=2)\n",
    "    fitting_df = new_train_df.copy() if new_train_df is not None else new_df.copy()\n",
    "    fitting_targets = fitting_df['TARGET']\n",
    "    fitting_df = fitting_df.drop(columns=['SK_ID_CURR'])\n",
    "    fitting_df = fitting_df.drop(columns=['TARGET'])\n",
    "    lda.fit(fitting_df[numerical_features], fitting_targets)\n",
    "    new_df['lda_1'] = lda.transform(new_df[numerical_features])\n",
    "\n",
    "    # New Features\n",
    "    new_df['amt_income_per_member'] = new_df['AMT_INCOME_TOTAL'] / new_df['CNT_FAM_MEMBERS']\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered_train_credit_application = engineer_feature(complete_train_credit_application)\n",
    "engineered_test_credit_application = engineer_feature(complete_test_credit_application, train_df=complete_train_credit_application)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered_train_credit_application.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_feature(df):\n",
    "    features = [\n",
    "#         'all',\n",
    "        \n",
    "#         'amt_income_per_member',\n",
    "        'lda_1',\n",
    "        \n",
    "#         'NAME_CONTRACT_TYPE',\n",
    "        'CODE_GENDER',\n",
    "#         'FLAG_OWN_CAR',\n",
    "#         'FLAG_OWN_REALTY',\n",
    "#         'CNT_CHILDREN',\n",
    "#         'AMT_INCOME_TOTAL',\n",
    "#         'AMT_ANNUITY',\n",
    "#         'AMT_GOODS_PRICE',\n",
    "#         'NAME_TYPE_SUITE',\n",
    "#         'NAME_INCOME_TYPE',\n",
    "#         'NAME_EDUCATION_TYPE',\n",
    "#         'NAME_FAMILY_STATUS',\n",
    "#         'NAME_HOUSING_TYPE',\n",
    "#         'REGION_POPULATION_RELATIVE',\n",
    "        'DAYS_BIRTH',\n",
    "#         'DAYS_EMPLOYED',\n",
    "        'DAYS_REGISTRATION',\n",
    "        'DAYS_ID_PUBLISH',\n",
    "#         'OWN_CAR_AGE',\n",
    "#         'OCCUPATION_TYPE',\n",
    "#         'REGION_RATING_CLIENT',\n",
    "#         'REGION_RATING_CLIENT_W_CITY',\n",
    "#         'WEEKDAY_APPR_PROCESS_START',\n",
    "#         'HOUR_APPR_PROCESS_START',\n",
    "#         'ORGANIZATION_TYPE',\n",
    "        'EXT_SOURCE_1',\n",
    "        'EXT_SOURCE_2',\n",
    "        'EXT_SOURCE_3',\n",
    "#         'OBS_30_CNT_SOCIAL_CIRCLE',\n",
    "#         'DEF_30_CNT_SOCIAL_CIRCLE',\n",
    "#         'OBS_60_CNT_SOCIAL_CIRCLE',\n",
    "#         'DEF_60_CNT_SOCIAL_CIRCLE',\n",
    "#         'DAYS_LAST_PHONE_CHANGE',\n",
    "    ]\n",
    "\n",
    "    if 'all' in features:\n",
    "        new_df = df.copy()\n",
    "    else:\n",
    "        new_df = pd.DataFrame()\n",
    "\n",
    "        new_df['SK_ID_CURR'] = df['SK_ID_CURR']\n",
    "        if 'TARGET' in df:\n",
    "            new_df['TARGET'] = df['TARGET']\n",
    "            \n",
    "        for basic_feature in features:\n",
    "            features_contain_basic = [feature for feature in df if basic_feature in feature]\n",
    "            for feature in features_contain_basic:\n",
    "                new_df[feature] = df[feature]\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_credit_application = select_feature(engineered_train_credit_application)\n",
    "test_credit_application = select_feature(engineered_test_credit_application)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_credit_application.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_categorical_data(df):  \n",
    "    if df is None:\n",
    "        return None\n",
    "    \n",
    "    new_df = df.copy()\n",
    "    \n",
    "    for col in categorical_features:\n",
    "        if col in new_df:\n",
    "            new_df = pd.get_dummies(new_df, columns=[col])\n",
    "            \n",
    "    # TODO: this is workaround for test data\n",
    "    if any('NAME_INCOME_TYPE' in col for col in new_df) and 'NAME_INCOME_TYPE_Maternity leave' not in new_df:\n",
    "        new_df['NAME_INCOME_TYPE_Maternity leave'] = 0\n",
    "            \n",
    "    return new_df\n",
    "\n",
    "def handle_numerical_data(df, train_df=None):\n",
    "    if df is None:\n",
    "        return None\n",
    "    \n",
    "    new_df = df.copy()\n",
    "    new_train_df = train_df.copy() if train_df is not None else None\n",
    "    \n",
    "    scale_df = new_train_df if new_train_df is not None else new_df\n",
    "    \n",
    "    for feature in numerical_features:\n",
    "        if feature in new_df and (scale_df[feature].dtype == np.float64 or scale_df[feature].dtype == np.int64):\n",
    "            stdsc = (preprocessing.StandardScaler()).fit(scale_df[feature].values.reshape(-1, 1))\n",
    "            new_df[feature] = stdsc.transform(new_df[feature].values.reshape(-1, 1))\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "def preprocess(df, train_df=None):\n",
    "    new_df = df.copy()\n",
    "    new_train_df = train_df.copy() if train_df is not None else None\n",
    "    \n",
    "    # Categorical Data\n",
    "    new_df = handle_categorical_data(new_df)\n",
    "    \n",
    "    # Numerical Data\n",
    "    new_df = handle_numerical_data(new_df, new_train_df)\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_credit_application = preprocess(train_credit_application)\n",
    "test_credit_application = preprocess(test_credit_application)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_credit_application = train_credit_application.reindex(np.random.permutation(train_credit_application.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check distribution if the randomization is fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_count = train_credit_application['SK_ID_CURR'].count()\n",
    "training_count = math.ceil(total_count * 0.75)\n",
    "validation_count = math.floor(total_count * 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_credit_application = train_credit_application.head(training_count)\n",
    "validation_credit_application = train_credit_application.tail(validation_count)\n",
    "testing_credit_application = test_credit_application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_ids_data_targets(df, dataframe=False):\n",
    "    new_df = df.copy()\n",
    "    \n",
    "    new_df_ids = new_df['SK_ID_CURR']\n",
    "    if 'TARGET' in new_df:\n",
    "        new_df_targets = new_df['TARGET']\n",
    "        new_df_data = new_df.drop(columns=['SK_ID_CURR', 'TARGET'])\n",
    "    else:\n",
    "        new_df_targets = None\n",
    "        new_df_data = new_df.drop(columns=['SK_ID_CURR'])\n",
    "    \n",
    "    \n",
    "    if not dataframe:\n",
    "        new_df_ids = new_df_ids.values\n",
    "        new_df_data = new_df_data.values\n",
    "        if new_df_targets is not None:\n",
    "            new_df_targets = new_df_targets.values\n",
    "    \n",
    "    return new_df_ids, new_df_data, new_df_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1, temp2, temp3 = split_ids_data_targets(training_credit_application, dataframe=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ids, training_data, training_targets = split_ids_data_targets(training_credit_application)\n",
    "validation_ids, validation_data, validation_targets = split_ids_data_targets(validation_credit_application)\n",
    "testing_ids, testing_data, testing_targets = split_ids_data_targets(testing_credit_application)\n",
    "\n",
    "training_targets_onehot = (preprocessing.OneHotEncoder().fit_transform(training_targets.reshape(-1, 1))).toarray()\n",
    "validation_targets_onehot = (preprocessing.OneHotEncoder().fit_transform(validation_targets.reshape(-1, 1))).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model, ensemble, svm\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sgd_classifier =  linear_model.SGDClassifier()\n",
    "sgd_classifier.fit(training_data, training_targets)\n",
    "\n",
    "training_predictions = sgd_classifier.predict(training_data)\n",
    "validation_predictions = sgd_classifier.predict(validation_data)\n",
    "\n",
    "print('Training   - acc: %.4f, auc: %.4f' % (metrics.accuracy_score(training_targets, training_predictions),\n",
    "                                             metrics.roc_auc_score(training_targets, training_predictions)))\n",
    "print('Validation - acc: %.4f, auc: %.4f' % (metrics.accuracy_score(validation_targets, validation_predictions),\n",
    "                                             metrics.roc_auc_score(validation_targets, validation_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression = linear_model.LogisticRegression(C=2)\n",
    "logistic_regression.fit(training_data, training_targets)\n",
    "\n",
    "training_predictions = logistic_regression.predict(training_data)\n",
    "validation_predictions = logistic_regression.predict(validation_data)\n",
    "\n",
    "print('Training   - acc: %.4f, auc: %.4f' % (metrics.accuracy_score(training_targets, training_predictions),\n",
    "                                             metrics.roc_auc_score(training_targets, training_predictions)))\n",
    "print('Validation - acc: %.4f, auc: %.4f' % (metrics.accuracy_score(validation_targets, validation_predictions),\n",
    "                                             metrics.roc_auc_score(validation_targets, validation_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "svm_classifier = svm.SVC()\n",
    "svm_classifier.fit(training_data, training_targets)\n",
    "\n",
    "training_predictions = svm_classifier.predict(training_data)\n",
    "validation_predictions = svm_classifier.predict(validation_data)\n",
    "\n",
    "print('Training   - acc: %.4f, auc: %.4f' % (metrics.accuracy_score(training_targets, training_predictions),\n",
    "                                             metrics.roc_auc_score(training_targets, training_predictions)))\n",
    "print('Validation - acc: %.4f, auc: %.4f' % (metrics.accuracy_score(validation_targets, validation_predictions),\n",
    "                                             metrics.roc_auc_score(validation_targets, validation_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_classifier = tree.DecisionTreeClassifier(max_depth=10)\n",
    "tree_classifier.fit(training_data, training_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_predictions = tree_classifier.predict(training_data)\n",
    "validation_predictions = tree_classifier.predict(validation_data)\n",
    "\n",
    "print('Training   - acc: %.4f, auc: %.4f' % (metrics.accuracy_score(training_targets, training_predictions),\n",
    "                                             metrics.roc_auc_score(training_targets, training_predictions)))\n",
    "print('Validation - acc: %.4f, auc: %.4f' % (metrics.accuracy_score(validation_targets, validation_predictions),\n",
    "                                             metrics.roc_auc_score(validation_targets, validation_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, value in enumerate(tree_classifier.feature_importances_.tolist()):\n",
    "    print('%s : %f' % (temp2.columns.values.tolist()[index], value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_classifier.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf_classifier = ensemble.RandomForestClassifier(n_estimators=30, criterion='gini', verbose=1)\n",
    "rf_classifier.fit(training_data, training_targets)\n",
    "\n",
    "training_predictions = rf_classifier.predict(training_data)\n",
    "validation_predictions = rf_classifier.predict(validation_data)\n",
    "\n",
    "print('Training   - acc: %.4f, auc: %.4f' % (metrics.accuracy_score(training_targets, training_predictions),\n",
    "                                             metrics.roc_auc_score(training_targets, training_predictions)))\n",
    "print('Validation - acc: %.4f, auc: %.4f' % (metrics.accuracy_score(validation_targets, validation_predictions),\n",
    "                                             metrics.roc_auc_score(validation_targets, validation_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "gb_classifier = ensemble.GradientBoostingClassifier()\n",
    "gb_classifier.fit(training_data, training_targets)\n",
    "\n",
    "training_predictions = gb_classifier.predict(training_data)\n",
    "validation_predictions = gb_classifier.predict(validation_data)\n",
    "\n",
    "print('Training   - acc: %.4f, auc: %.4f' % (metrics.accuracy_score(training_targets, training_predictions),\n",
    "                                             metrics.roc_auc_score(training_targets, training_predictions)))\n",
    "print('Validation - acc: %.4f, auc: %.4f' % (metrics.accuracy_score(validation_targets, validation_predictions),\n",
    "                                             metrics.roc_auc_score(validation_targets, validation_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_metric(y_true, y_pred):\n",
    "    return tf.Variable(metrics.roc_auc_score(y_true, y_pred), name='auc_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_activation = 'sigmoid'\n",
    "default_last_activation = 'sigmoid'\n",
    "default_batch_size = 1000\n",
    "default_epochs = 30\n",
    "\n",
    "dnn_classifier_settings = []\n",
    "\n",
    "default_dnn_classifier_settings = [\n",
    "#     # Adam\n",
    "#     {'optimizer': optimizers.Adam(), 'batch_size': default_batch_size, 'epochs': default_epochs, \n",
    "#      'activation': default_activation, 'last_activation': default_last_activation,\n",
    "#      'acc': None, 'val_acc': None, 'history': None, 'auc': None, 'val_auc': None,\n",
    "#      'training_predictions_onehot': None, 'validation_predictions_onehot': None},\n",
    "    \n",
    "# #     # SGD\n",
    "# #     {'optimizer': optimizers.SGD(momentum=0.1), 'batch_size': default_batch_size, 'epochs': default_epochs * 10,\n",
    "# #      'activation': default_activation, 'last_activation': default_last_activation,\n",
    "# #      'acc': None, 'val_acc': None, 'history': None, 'auc': None, 'val_auc': None,\n",
    "# #      'training_predictions': None, 'validation_predictions': None},\n",
    "    \n",
    "#     # Adagrad\n",
    "#     {'optimizer': optimizers.Adagrad(), 'batch_size': default_batch_size, 'epochs': default_epochs, \n",
    "#      'activation': default_activation, 'last_activation': default_last_activation,\n",
    "#      'acc': None, 'val_acc': None, 'history': None, 'auc': None, 'val_auc': None,\n",
    "#      'training_predictions': None, 'validation_predictions': None},\n",
    "    \n",
    "#     # RMSprop\n",
    "#     {'optimizer': optimizers.RMSprop(), 'batch_size': default_batch_size, 'epochs': default_epochs, \n",
    "#      'activation': default_activation, 'last_activation': default_last_activation,\n",
    "#      'acc': None, 'val_acc': None, 'history': None, 'auc': None, 'val_auc': None,\n",
    "#      'training_predictions': None, 'validation_predictions': None},\n",
    "    \n",
    "#     # Adamax\n",
    "#     {'optimizer': optimizers.Adamax(), 'batch_size': default_batch_size, 'epochs': default_epochs, \n",
    "#      'activation': default_activation, 'last_activation': default_last_activation,\n",
    "#      'acc': None, 'val_acc': None, 'history': None, 'auc': None, 'val_auc': None,\n",
    "#      'training_predictions': None, 'validation_predictions': None},\n",
    "    \n",
    "#     # Nadam\n",
    "#     {'optimizer': optimizers.Nadam(), 'batch_size': default_batch_size, 'epochs': default_epochs, \n",
    "#      'activation': default_activation, 'last_activation': default_last_activation,\n",
    "#      'acc': None, 'val_acc': None, 'history': None, 'auc': None, 'val_auc': None,\n",
    "#      'training_predictions': None, 'validation_predictions': None},\n",
    "]\n",
    "\n",
    "dnn_classifier_settings.extend(default_dnn_classifier_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_settings = [\n",
    "    # Adam\n",
    "    {'optimizer': optimizers.Adam(lr=0.0001), 'batch_size': default_batch_size, 'epochs': default_epochs, \n",
    "     'activation': default_activation, 'last_activation': default_last_activation,\n",
    "     'acc': None, 'val_acc': None, 'history': None, 'auc': None, 'val_auc': None,\n",
    "     'training_predictions_onehot': None, 'validation_predictions_onehot': None},\n",
    "    {'optimizer': optimizers.Adam(lr=0.001), 'batch_size': default_batch_size, 'epochs': default_epochs, \n",
    "     'activation': default_activation, 'last_activation': default_last_activation,\n",
    "     'acc': None, 'val_acc': None, 'history': None, 'auc': None, 'val_auc': None,\n",
    "     'training_predictions_onehot': None, 'validation_predictions_onehot': None},\n",
    "    {'optimizer': optimizers.Adam(lr=0.01), 'batch_size': default_batch_size, 'epochs': default_epochs, \n",
    "     'activation': default_activation, 'last_activation': default_last_activation,\n",
    "     'acc': None, 'val_acc': None, 'history': None, 'auc': None, 'val_auc': None,\n",
    "     'training_predictions_onehot': None, 'validation_predictions_onehot': None},\n",
    "]\n",
    "\n",
    "if len(new_settings) > 0:\n",
    "    dnn_classifier_settings.extend(new_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, dnn_classifier_setting in enumerate(dnn_classifier_settings):\n",
    "    if dnn_classifier_setting['acc'] is None and dnn_classifier_setting['val_acc'] is None and dnn_classifier_setting['history'] is None:\n",
    "        optimizer = dnn_classifier_setting['optimizer']\n",
    "        batch_size = dnn_classifier_setting['batch_size']\n",
    "        epochs = dnn_classifier_setting['epochs']\n",
    "        activation = dnn_classifier_setting['activation']\n",
    "        last_activation = dnn_classifier_setting['last_activation']\n",
    "\n",
    "        dnn_classifier = Sequential()\n",
    "        input_shape = (training_data.shape[1], )\n",
    "        dnn_classifier.add(Dense(128, activation=activation, input_shape=input_shape))\n",
    "        # dnn_classifier.add(Dropout(rate=0.35))\n",
    "        dnn_classifier.add(Dense(128, activation=activation))\n",
    "        # dnn_classifier.add(Dropout(rate=0.35))\n",
    "        dnn_classifier.add(Dense(64, activation=activation))\n",
    "        # dnn_classifier.add(Dropout(rate=0.25))\n",
    "        dnn_classifier.add(Dense(2, activation=last_activation))\n",
    "        dnn_classifier.compile(loss='binary_crossentropy', \n",
    "                               optimizer=optimizer,\n",
    "                               metrics=['acc'])\n",
    "        history = dnn_classifier.fit(training_data, training_targets_onehot,\n",
    "                          epochs=epochs, batch_size=batch_size, verbose=False, shuffle=True,\n",
    "                          validation_data=(validation_data, validation_targets_onehot))\n",
    "\n",
    "        dnn_classifier_setting['history'] = history\n",
    "        \n",
    "        training_predictions_onehot = dnn_classifier.predict(training_data)\n",
    "        training_predictions = pd.DataFrame(training_predictions_onehot).apply(lambda val: 1.0 if val[1] > 0.3 else 0.0, axis=1)\n",
    "        \n",
    "        validation_predictions_onehot = dnn_classifier.predict(validation_data)\n",
    "        validation_predictions = pd.DataFrame(validation_predictions_onehot).apply(lambda val: 1.0 if val[1] > 0.3 else 0.0, axis=1)\n",
    "        \n",
    "        dnn_classifier_setting['training_predictions_onehot'] = training_predictions_onehot\n",
    "        dnn_classifier_setting['validation_predictions_onehot'] = validation_predictions_onehot\n",
    "        dnn_classifier_setting['acc'] = metrics.accuracy_score(training_targets, training_predictions)\n",
    "        dnn_classifier_setting['val_acc'] = metrics.accuracy_score(validation_targets, validation_predictions)\n",
    "        dnn_classifier_setting['auc'] = metrics.roc_auc_score(training_targets, training_predictions)\n",
    "        dnn_classifier_setting['val_auc'] = metrics.roc_auc_score(validation_targets, validation_predictions)\n",
    "\n",
    "    print('%2d: Optimizer: %10s; LR: %.5f; bs: %3d; epochs: %4d; acc: %.4f; val_acc: %.4f; auc: %.2f; val_auc: %.2f' % (index, \n",
    "                                                                                              type(dnn_classifier_setting['optimizer']).__name__, \n",
    "                                                                                              dnn_classifier_setting['optimizer'].get_config()['lr'], \n",
    "                                                                                              dnn_classifier_setting['batch_size'], \n",
    "                                                                                              dnn_classifier_setting['epochs'],\n",
    "                                                                                              dnn_classifier_setting['acc'], \n",
    "                                                                                              dnn_classifier_setting['val_acc'],\n",
    "                                                                                              dnn_classifier_setting['auc'],\n",
    "                                                                                              dnn_classifier_setting['val_auc']))\n",
    "\n",
    "IPython.display.Audio('http://www.pacdv.com/sounds/interface_sound_effects/sound94.wav', autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(15, 4))\n",
    "for dnn_classifier_setting in dnn_classifier_settings:\n",
    "    plt.plot(dnn_classifier_setting['history'].history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(15, 20))\n",
    "for index, setting in enumerate(dnn_classifier_settings):\n",
    "    plt.subplot(10, 2, index + 1)\n",
    "    plt.title('Config %d' % index)\n",
    "    pd.Series(setting['training_predictions_onehot'][:, 1]).hist(bins=100)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary_range = np.linspace(0.01, 0.5, 10)\n",
    "\n",
    "for boundary in boundary_range:\n",
    "    training_predictions = dnn_classifier_settings[1]['training_predictions_onehot'] / boundary * 0.5\n",
    "    validation_predictions = dnn_classifier_settings[1]['validation_predictions_onehot'] / boundary * 0.5\n",
    "    training_predictions = pd.DataFrame(training_predictions).apply(lambda val: 1.0 if val[1] > 0.5 else 0.0, axis=1)\n",
    "    validation_predictions = pd.DataFrame(validation_predictions).apply(lambda val: 1.0 if val[1] > 0.5 else 0.0, axis=1)\n",
    "    print('boundary: %.4f, training AUC score: %.4f, val AUC score: %.4f' % (boundary, metrics.roc_auc_score(training_targets, training_predictions), metrics.roc_auc_score(validation_targets, validation_predictions)))\n",
    "    \n",
    "IPython.display.Audio('http://www.pacdv.com/sounds/interface_sound_effects/sound94.wav', autoplay=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = dnn_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_predictions = classifier.predict(training_data)\n",
    "print('Classifier: %s - acc: %.4f, auc: %.4f' % (classifier.__class__.__name__,\n",
    "                                                 metrics.accuracy_score(training_targets, training_predictions),\n",
    "                                                 metrics.roc_auc_score(training_targets, training_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## training_predictions = classifier.predict(training_data)\n",
    "print(training_predictions)\n",
    "if type(classifier) == Sequential:\n",
    "    training_predictions = pd.DataFrame(training_predictions).apply(lambda val: 1.0 if val[1] > 0.1 else 0.0, axis=1)\n",
    "    validation_predictions = classifier.predict(validation_data)\n",
    "    validation_predictions = pd.DataFrame(validation_predictions).apply(lambda val: 1.0 if val[1] > 0.1 else 0.0, axis=1)\n",
    "else:\n",
    "    print(training_predictions.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.accuracy_score(training_targets, training_predictions))\n",
    "print(metrics.roc_auc_score(training_targets, training_predictions))\n",
    "print(metrics.accuracy_score(validation_targets, validation_predictions))\n",
    "print(metrics.roc_auc_score(validation_targets, validation_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare submission.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
